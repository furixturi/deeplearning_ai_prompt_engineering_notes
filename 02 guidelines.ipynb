{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2 Guidelines for Prompting\n",
    "[Course](https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/2/guidelines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principles of Prompting\n",
    "1. Write clear and specific prompts.\n",
    "2. Give the model time to \"think\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 691 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-macosx_11_0_arm64.whl (338 kB)\n",
      "\u001b[K     |████████████████████████████████| 338 kB 14.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from openai) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (4.0.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-macosx_11_0_arm64.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-macosx_11_0_arm64.whl (35 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/xiaolishen/opt/miniconda3/lib/python3.9/site-packages (from aiohttp->openai) (2.0.4)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load API key and relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# load ENVs from a local .env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper function\n",
    "\n",
    "We'll be using the ChatGPT model \"gpt-3.5-turbo\" and OpenAI's [Chat completion endpoint](https://platform.openai.com/docs/guides/chat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = 0, # the degree of randomness of the model's output\n",
    "    )\n",
    "    # print(response)\n",
    "    return response.choices[0].message[\"content\"]\n",
    "    # return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle 1: Write clear and specific instructions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactics\n",
    "1. Use delimiters to clearly indicate distinct parts of the input\n",
    "2. Ask for a structured output\n",
    "3. Ask the model to check whether conditions are satisfied\n",
    "4. \"Few-shot\" prompting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like: ` ``` `, `\"\"\"`, `< >`, `<tag></tag>`, `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"To guide a model towards the desired output and reduce the chances of irrelevant or incorrect responses, it is important to provide clear and specific instructions, which may require longer prompts for more clarity and context.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1683081517,\n",
      "  \"id\": \"chatcmpl-7Bwg1sXSNIfucROYXl3TY1AiOOTCx\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 39,\n",
      "    \"prompt_tokens\": 134,\n",
      "    \"total_tokens\": 173\n",
      "  }\n",
      "}\n",
      "To guide a model towards the desired output and reduce the chances of irrelevant or incorrect responses, it is important to provide clear and specific instructions, which may require longer prompts for more clarity and context.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\\n",
    "    into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 2: Ask for a structured output\n",
    "- JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"| book_id | title | author | genre | publish_date | publish_city |\\n|---------|-------|--------|-------|--------------|--------------|\\n| 1 | The Hobbit | J.R.R. Tolkien | Fantasy | September 21, 1937 | London |\\n| 2 | The Lord of the Rings | J.R.R. Tolkien | Fantasy | July 29, 1954 | London |\\n| 3 | The Silmarillion | J.R.R. Tolkien | Fantasy | September 15, 1977 | London |\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1683082591,\n",
      "  \"id\": \"chatcmpl-7BwxLSlbynMtUlwXK4D4KDNcXSnsW\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 110,\n",
      "    \"prompt_tokens\": 58,\n",
      "    \"total_tokens\": 168\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three Tolkien's books with the title, genre, first published date and city. \\\n",
    "    Provide them in markdown table format with the following table headers:\n",
    "    book_id, title, author, genre, publish_date, publish_city.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| book_id | title | author | genre | publish_date | publish_city |\n",
      "|---------|-------|--------|-------|--------------|--------------|\n",
      "| 1 | The Hobbit | J.R.R. Tolkien | Fantasy | September 21, 1937 | London |\n",
      "| 2 | The Lord of the Rings | J.R.R. Tolkien | Fantasy | July 29, 1954 | London |\n",
      "| 3 | The Silmarillion | J.R.R. Tolkien | Fantasy | September 15, 1977 | London |\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| book_id | title | author | genre | publish_date | publish_city |\n",
    "|---------|-------|--------|-------|--------------|--------------|\n",
    "| 1 | The Hobbit | J.R.R. Tolkien | Fantasy | September 21, 1937 | London |\n",
    "| 2 | The Lord of the Rings | J.R.R. Tolkien | Fantasy | July 29, 1954 | London |\n",
    "| 3 | The Silmarillion | J.R.R. Tolkien | Fantasy | September 15, 1977 | London |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 3: Ask the model to check whether conditions are satisfied\n",
    "We let the model extract steps if the input text contains a sequence of instructions, otherwise output \"no steps provided\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some water boiling. \\\n",
    "    While that's happening, grab a cup and put a tea bag in it. \\\n",
    "    Once the water is hot enough, just pour it over the tea bag. \\\n",
    "    Let it sit for a bit so the tea can steep. \n",
    "    After a few minutes, take out the tea bag. \\\n",
    "    If you like, you can add some sugar or milk to taste. \\\n",
    "And that's it! You've got yourself a delicious cup of tea to enjoy.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \\\n",
    "    If it contains a sequence of instructions, \\\n",
    "    re-write those instructions in the following format:\n",
    "    \n",
    "Step 1 - ...\n",
    "Step 2 - ...\n",
    "...\n",
    "Step N - ...\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\\n",
    "    then simply write \\\"No steps provided.\\\"\n",
    "    \n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - Add some sugar or milk to taste.\n",
      "Step 7 - Enjoy your delicious cup of tea!\n"
     ]
    }
   ],
   "source": [
    "print(\"Completion for Text 1:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2 = text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are \\\n",
    "singing. It's a beautiful day to go for a \\ \n",
    "walk in the park. The flowers are blooming, and the \\ \n",
    "trees are swaying gently in the breeze. People \\ \n",
    "are out and about, enjoying the lovely weather. \\ \n",
    "Some are having picnics, while others are playing \\ \n",
    "games or simply relaxing on the grass. It's a \\ \n",
    "perfect day to spend time outdoors and appreciate the \\ \n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \\\n",
    "    If it contains a sequence of instructions, \\\n",
    "    re-write those instructions in the following format:\n",
    "    \n",
    "Step 1 - ...\n",
    "Step 2 - ...\n",
    "...\n",
    "Step N - ...\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\\n",
    "    then simply write \\\"No steps provided.\\\"\n",
    "    \n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "print(\"Completion for Text 2:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactic 4: \"Few-shot\" prompting\n",
    "Give it example(s) to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: Resilience is like a tree that bends with the wind but does not break. It is the ability to bounce back from adversity and overcome challenges. Just like a tree needs strong roots to withstand the storm, we need to cultivate inner strength and perseverance to face life's obstacles. Remember, every setback is an opportunity to grow stronger and wiser.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that arves the deepest valley flows from a modest spring;\n",
    "    the grandest symphony originates from a single note;\n",
    "    the most intricate tapestry begins with a solitary thread.\n",
    "    \n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle 2: Give the model time to \"think\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a model is making reasoning errors by rushing to an incorrect conclusion, you should try reframing the query \n",
    "to request a chain or series of relevant reasoning before the model provides its final answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tactics\n",
    "1. Specify the steps required to complete a task\n",
    "2. Instruct the model to work out its own solution before rushing to a conclusion\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "Two siblings, Jack and Jill, go on a quest to fetch water from a well on a hilltop, but misfortune strikes and they both tumble down the hill, returning home slightly battered but with their adventurous spirits undimmed.\n",
      "\n",
      "2つの兄弟、ジャックとジルは、丘の上の井戸から水を取るためにクエストに出かけますが、不幸が襲い、両方が丘を転がり落ち、少し傷ついて家に帰りますが、彼らの冒険心は減退しませんでした。\n",
      "\n",
      "ジャック、ジル\n",
      "\n",
      "{\n",
      "  \"japanese_summary\": \"2つの兄弟、ジャックとジルは、丘の上の井戸から水を取るためにクエストに出かけますが、不幸が襲い、両方が丘を転がり落ち、少し傷ついて家に帰りますが、彼らの冒険心は減退しませんでした。\",\n",
      "  \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions:\n",
    "1 - Summarize the following text delimited by triple backticks with 1 sentence\n",
    "2 - Translate the summary into Japanese\n",
    "3 - List each name in the Japanese summary\n",
    "4 - Output a json object that contains the following keys: japenese_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's give it a better prompt with format instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 2:\n",
      "Summary: Siblings Jack and Jill go on a quest to fetch water from a hilltop well, but misfortune strikes and they tumble down the hill, returning home slightly battered but with undimmed adventurous spirits. \n",
      "Translation: 兄妹杰克和吉尔前往山顶井取水，但不幸摔倒滚下山，虽然受了点伤，但他们的冒险精神仍然不减，继续愉快地探索。\n",
      "Names: Jack, Jill\n",
      "Output JSON: {\"chinese_summary\": \"兄妹杰克和吉尔前往山顶井取水，但不幸摔倒滚下山，虽然受了点伤，但他们的冒险精神仍然不减，继续愉快地探索。\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "\n",
    "# example 2\n",
    "prompt_2 = f\"\"\"\n",
    "Perform the following actions:\n",
    "1 - Summarize the following text delimited by <> backticks with 1 sentence\n",
    "2 - Translate the summary into Chinese\n",
    "3 - List each name in the Chinese summary\n",
    "4 - Output a json object that contains the following keys: chinese_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in the translated summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text:\n",
    "<{text}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt_2)\n",
    "print(\"Completion for prompt 2:\")\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tactic 2: Instruct the model to work out its own solotion before rushing to a conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The student's solution is actually incorrect. So let's ask the model to work out its own solution first, then compare with the student's solution to determine if the student's solution is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Question: What is the total cost for the first year of operations as a function of the number of square feet?\n",
      "\n",
      "- Correct solution: Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "\n",
      "- Student's solution: Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 100x\n",
      "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
      "\n",
      "- Comparison: The student's solution is incorrect because they added $100 per square foot for maintenance instead of $10 per square foot.\n",
      "\n",
      "- Grade: 0\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a very strict teacher. Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Output the question, your solution, the student's solution, the comparison, and the student's grade.\n",
    "Use the following format:\n",
    "\n",
    "- Question: the question\n",
    "\n",
    "- Correct solution: the correct solution\n",
    "\n",
    "- Student's solution: the student's solution\n",
    "\n",
    "- Comparison:\n",
    "\n",
    "- Grade: 100 if the solution is correct, 0 if incorrect\n",
    "\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Output:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Limitations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hallucinations\n",
    "Models sometimes make statements that sound plausible but are not true.\n",
    "\n",
    "##### To reduce hallucinations:\n",
    "Tirst ask the model to find relevant information, then answer the question based on the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I don't have personal experience or emotions, but I can provide you with information about the AeroGlide UltraSlim Smart Toothbrush by Gillette. \n",
      "\n",
      "The AeroGlide UltraSlim Smart Toothbrush is a high-tech toothbrush that uses advanced technology to provide a superior brushing experience. It features a slim, lightweight design that makes it easy to hold and maneuver, and it uses sonic vibrations to clean teeth and remove plaque. \n",
      "\n",
      "The toothbrush also comes with a companion app that provides real-time feedback on your brushing technique, helping you to improve your oral hygiene habits. The app tracks your brushing time, pressure, and coverage, and it provides personalized recommendations for improving your brushing technique. \n",
      "\n",
      "The AeroGlide UltraSlim Smart Toothbrush also has a long battery life, lasting up to two weeks on a single charge. It comes with a charging base that doubles as a storage case, making it easy to take with you on the go. \n",
      "\n",
      "Overall, the AeroGlide UltraSlim Smart Toothbrush is a high-quality toothbrush that uses advanced technology to provide a superior brushing experience. It's a great choice for anyone who wants to improve their oral hygiene habits and maintain a healthy smile.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Gillette\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gillette is a brand that is primarily known for its shaving products, including razors, shaving creams, and aftershaves. The brand was founded in 1901 by King C. Gillette and has since become a household name in the personal care industry.\n",
      "\n",
      "In recent years, Gillette has expanded its product line to include other personal care items, such as deodorants and body washes. One of the brand's newest products is the AeroGlide UltraSlim Smart Toothbrush.\n",
      "\n",
      "According to Gillette's website, the AeroGlide UltraSlim Smart Toothbrush is designed to provide a superior clean with its advanced sonic technology. The toothbrush features a slim, ergonomic handle and a brush head that is designed to reach every corner of the mouth.\n",
      "\n",
      "The toothbrush also comes with a mobile app that allows users to track their brushing habits and receive personalized recommendations for improving their oral hygiene. The app also features a timer that helps users ensure they are brushing for the recommended two minutes.\n",
      "\n",
      "Overall, the AeroGlide UltraSlim Smart Toothbrush by Gillette appears to be a high-tech and innovative product that is designed to help users improve their oral hygiene.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Find relevant information on Gillette. Then tell me about AeroGlide UltraSlim Smart Toothbrush by Gillette citing your sources.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
